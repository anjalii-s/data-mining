# -*- coding: utf-8 -*-
"""Copy of Python code website evaluation using opinion mining.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vaBDPBGFx94q-m4SGGfQXrPH_W_euC43

# VADER
"""

import kagglehub
import pandas as pd
import nltk
import matplotlib.pyplot as plt
import os

# Ensure all required NLTK data is downloaded
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('vader_lexicon', quiet=True)

from nltk.tokenize import word_tokenize
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download the Amazon Sales Dataset
try:
    path = kagglehub.dataset_download("karkavelrajaj/amazon-sales-dataset")
    print("Path to dataset files:", path)

    # Locate the CSV file
    csv_file = os.path.join(path, 'amazon.csv')

    # Load the dataset
    df = pd.read_csv(csv_file)
except Exception as e:
    print(f"Error loading dataset: {e}")
    exit()

# Check required columns
if 'review_content' not in df.columns:
    print("Error: 'review_content' column not found")
    exit()

# Clean the rating column - convert to numeric, handle non-numeric values
if 'rating' in df.columns:
    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')

print("\nSample reviews and ratings:")
print(df[['review_content', 'rating']].head())

# Initialize VADER
vader = SentimentIntensityAnalyzer()

# Aspect definitions
aspects = {
    'product authenticity': ['quality', 'durable', 'sturdy', 'break', 'broken', 'last', 'material'],
    'customer support ': ['support', 'helpful', 'rude', 'response', 'service', 'unhelpful'],
    'delivery reliability': ['delivery', 'ship', 'arrive', 'late', 'early', 'shipping', 'package'],
    'value for money': ['price', 'worth', 'expensive', 'cheap', 'affordable', 'overpriced']
}

def analyze_sentiment(text):
    """Analyze sentiment using VADER with error handling"""
    if not isinstance(text, str) or not text.strip():
        return 'neutral'
    try:
        scores = vader.polarity_scores(text)
        if scores['compound'] >= 0.05:
            return 'positive'
        elif scores['compound'] <= -0.05:
            return 'negative'
        return 'neutral'
    except:
        return 'neutral'

# Initialize results with all sentiment categories
results = {
    aspect: {
        'positive': 0,
        'negative': 0,
        'neutral': 0,
        'total': 0
    } for aspect in aspects
}

overall_rating = 0
valid_ratings = 0

# Process reviews
for _, row in df.iterrows():
    review_text = row['review_content'] if pd.notna(row['review_content']) else ''

    # Safely get rating (already converted to numeric)
    rating = row['rating'] if 'rating' in df.columns and pd.notna(row['rating']) else None

    sentiment = analyze_sentiment(review_text)

    # Check for aspect mentions
    text_lower = review_text.lower()
    for aspect, keywords in aspects.items():
        for keyword in keywords:
            if keyword in text_lower:
                results[aspect]['total'] += 1
                results[aspect][sentiment] += 1
                break  # Count each aspect only once per review

    # Track overall rating if available
    if rating is not None:
        overall_rating += rating
        valid_ratings += 1

# Calculate ratings (1-5 scale)
for aspect in results:
    total = results[aspect]['total']
    if total > 0:
        pos = results[aspect]['positive']
        neg = results[aspect]['negative']
        # Scale rating between 1-5 based on sentiment ratio
        results[aspect]['rating'] = 1 + 4 * (pos / (pos + neg)) if (pos + neg) > 0 else 3.0
    else:
        results[aspect]['rating'] = 3.0  # Neutral

# Calculate overall average rating
overall_rating = overall_rating / valid_ratings if valid_ratings > 0 else 0

# Print results
print(f"\nAnalysis Results:")
print(f"Total reviews: {len(df)}")
print(f"Valid ratings: {valid_ratings}")
print(f"Overall rating: {overall_rating:.2f}/5")

print("\nAspect Breakdown:")
for aspect, data in results.items():
    print(f"\n{aspect.replace('_', ' ').title()}:")
    print(f"  Total mentions: {data['total']}")
    print(f"  Positive: {data['positive']} ({data['positive']/data['total']*100:.1f}%)" if data['total'] > 0 else "  Positive: 0")
    print(f"  Negative: {data['negative']} ({data['negative']/data['total']*100:.1f}%)" if data['total'] > 0 else "  Negative: 0")
    print(f"  Neutral: {data['neutral']} ({data['neutral']/data['total']*100:.1f}%)" if data['total'] > 0 else "  Neutral: 0")
    print(f"  Rating: {data['rating']:.2f}/5")

# Visualization
plt.figure(figsize=(12, 6))
aspect_names = [a.replace('_', ' ').title() for a in aspects]
ratings = [results[a]['rating'] for a in aspects]

colors = ['#4CAF50', '#2196F3', '#FFC107', '#FF5722']
bars = plt.bar(aspect_names, ratings, color=colors, edgecolor='black')

plt.title('Amazon Product Aspect Ratings (VADER Sentiment Analysis)', fontsize=14)
plt.xlabel('Product Aspects', fontsize=12)
plt.ylabel('Rating (1-5 scale)', fontsize=12)
plt.ylim(1, 5)
plt.grid(axis='y', alpha=0.3)

# Add value labels
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height,
             f'{height:.2f}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.savefig('amazon_aspect_ratings_vader.png', dpi=300)
plt.show()

"""# BERT"""

import pandas as pd
import torch
from transformers import BertTokenizer, BertForSequenceClassification
from transformers import pipeline
import matplotlib.pyplot as plt

# Load dataset (assuming you already have df from previous code)
# df = pd.read_csv('amazon.csv')

# Initialize BERT model for sentiment analysis
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"
tokenizer = BertTokenizer.from_pretrained(model_name)
model = BertForSequenceClassification.from_pretrained(model_name)

# Create sentiment analysis pipeline
sentiment_analyzer = pipeline(
    "sentiment-analysis",
    model=model,
    tokenizer=tokenizer,
    device=0 if torch.cuda.is_available() else -1
)

# Aspect keywords (same as VADER implementation for fair comparison)
aspects = {
    'product authenticity': ['quality', 'durable', 'material', 'genuine', 'fake'],
    'customer support': ['support', 'service', 'response', 'help', 'complaint'],
    'delivery reliability': ['delivery', 'shipping', 'arrived', 'late', 'early'],
    'value for money': ['price', 'worth', 'expensive', 'cheap', 'affordable']
}

def bert_aspect_sentiment(text, aspect_keywords):
    """Analyze sentiment for specific aspects using BERT"""
    if not isinstance(text, str):
        return 3.0  # Neutral if no text

    # Check if any aspect keyword exists in text
    text_lower = text.lower()
    if not any(keyword in text_lower for keyword in aspect_keywords):
        return None  # Skip if no aspect mentioned

    # Truncate to BERT's max length (512 tokens)
    truncated_text = text[:512]

    try:
        result = sentiment_analyzer(truncated_text)[0]
        # Convert BERT's 1-5 star rating to 1-5 scale
        return float(result['label'].split()[0])
    except:
        return 3.0  # Neutral if analysis fails

# Initialize results storage
bert_results = {aspect: [] for aspect in aspects}

# Process reviews (sampling for speed - remove .sample() for full analysis)
for _, row in df.sample(1000).iterrows():  # Reduced for demo - increase for better accuracy
    review = str(row['review_content'])

    for aspect, keywords in aspects.items():
        score = bert_aspect_sentiment(review, keywords)
        if score is not None:
            bert_results[aspect].append(score)

# Calculate average ratings
final_ratings = {
    aspect: sum(scores)/len(scores) if scores else 3.0
    for aspect, scores in bert_results.items()
}

# Print results
print("\nBERT Aspect Analysis Results:")
for aspect, rating in final_ratings.items():
    print(f"{aspect.title()}: {rating:.2f}/5 (based on {len(bert_results[aspect])} reviews)")

# Visualization for comparison with VADER
plt.figure(figsize=(12, 6))
colors = ['#FF9AA2', '#FFB7B2', '#FFDAC1', '#E2F0CB']
bars = plt.bar(final_ratings.keys(), final_ratings.values(), color=colors, edgecolor='black')

plt.title('Amazon Aspect Ratings (BERT Sentiment Analysis)', fontsize=14)
plt.xlabel('Product Aspects', fontsize=12)
plt.ylabel('Rating (1-5 scale)', fontsize=12)
plt.ylim(1, 5)
plt.grid(axis='y', alpha=0.3)

# Add value labels
for bar in bars:
    height = bar.get_height()
    plt.text(bar.get_x() + bar.get_width()/2, height,
             f'{height:.2f}', ha='center', va='bottom', fontsize=10)

plt.tight_layout()
plt.savefig('bert_aspect_ratings.png', dpi=300)
plt.show()

"""# Roberta (not in presentation)"""

import kagglehub
import pandas as pd
import nltk
import os
from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification
from nltk.tokenize import word_tokenize

# Download required NLTK data
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)

# Download the Amazon Sales Dataset
try:
    path = kagglehub.dataset_download("karkavelrajaj/amazon-sales-dataset")
    print("Path to dataset files:", path)

    # Locate the CSV file
    csv_file = os.path.join(path, 'amazon.csv')

    # Load the dataset
    df = pd.read_csv(csv_file)
except Exception as e:
    print(f"Error loading dataset: {e}")
    exit()

# Check required columns
if 'review_content' not in df.columns:
    print("Error: 'review_content' column not found")
    exit()

# Clean the rating column - convert to numeric, handle non-numeric values
if 'rating' in df.columns:
    df['rating'] = pd.to_numeric(df['rating'], errors='coerce')

print("\nSample reviews and ratings:")
print(df[['review_content', 'rating']].head())

# Initialize RoBERTa sentiment analyzer
model_name = "cardiffnlp/twitter-roberta-base-sentiment"
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)
sentiment_analyzer = pipeline("sentiment-analysis", model=model, tokenizer=tokenizer)

# Aspect definitions
aspects = {
    'product authenticity': ['quality', 'durable', 'sturdy', 'break', 'broken', 'last', 'material'],
    'customer support quality': ['support', 'helpful', 'rude', 'response', 'service', 'unhelpful'],
    'delivery reliability': ['delivery', 'ship', 'arrive', 'late', 'early', 'shipping', 'package'],
    'value for money': ['price', 'worth', 'expensive', 'cheap', 'affordable', 'overpriced']
}

def analyze_sentiment(text):
    """Analyze sentiment using RoBERTa with error handling"""
    if not isinstance(text, str) or not text.strip():
        return 'neutral'
    try:
        result = sentiment_analyzer(text, truncation=True, max_length=512)[0]
        label = result['label'].lower()
        if 'positive' in label:
            return 'positive'
        elif 'negative' in label:
            return 'negative'
        return 'neutral'
    except:
        return 'neutral'

# Initialize results with all sentiment categories
results = {
    aspect: {
        'positive': 0,
        'negative': 0,
        'neutral': 0,
        'total': 0
    } for aspect in aspects
}

overall_rating = 0
valid_ratings = 0

# Process reviews
for _, row in df.iterrows():
    review_text = row['review_content'] if pd.notna(row['review_content']) else ''

    # Safely get rating (already converted to numeric)
    rating = row['rating'] if 'rating' in df.columns and pd.notna(row['rating']) else None

    sentiment = analyze_sentiment(review_text)

    # Check for aspect mentions
    text_lower = review_text.lower()
    for aspect, keywords in aspects.items():
        for keyword in keywords:
            if keyword in text_lower:
                results[aspect]['total'] += 1
                results[aspect][sentiment] += 1
                break  # Count each aspect only once per review

    # Track overall rating if available
    if rating is not None:
        overall_rating += rating
        valid_ratings += 1

# Calculate ratings (1-5 scale)
for aspect in results:
    total = results[aspect]['total']
    if total > 0:
        pos = results[aspect]['positive']
        neg = results[aspect]['negative']
        # Scale rating between 1-5 based on sentiment ratio
        results[aspect]['rating'] = 1 + 4 * (pos / (pos + neg)) if (pos + neg) > 0 else 3.0
    else:
        results[aspect]['rating'] = 3.0  # Neutral

# Calculate overall average rating
overall_rating = overall_rating / valid_ratings if valid_ratings > 0 else 0

# Print results
print(f"\nAnalysis Results (RoBERTa):")
print(f"Total reviews: {len(df)}")
print(f"Valid ratings: {valid_ratings}")
print(f"Overall rating: {overall_rating:.2f}/5")

print("\nAspect Breakdown:")
for aspect, data in results.items():
    print(f"\n{aspect.title()}:")
    print(f"  Total mentions: {data['total']}")
    print(f"  Positive: {data['positive']} ({data['positive']/data['total']*100:.1f}%)" if data['total'] > 0 else "  Positive: 0")
    print(f"  Negative: {data['negative']} ({data['negative']/data['total']*100:.1f}%)" if data['total'] > 0 else "  Negative: 0")
    print(f"  Neutral: {data['neutral']} ({data['neutral']/data['total']*100:.1f}%)" if data['total'] > 0 else "  Neutral: 0")
    print(f"  Rating: {data['rating']:.2f}/5")

"""#BERT

# Roberta ((not in presentation))
"""

from transformers import pipeline

# Load RoBERTa sentiment analysis pipeline
sentiment_analysis = pipeline("sentiment-analysis", model="siebert/sentiment-roberta-large-english")

# Sample text
text = "I had an amazing experience with this product!"

# Perform sentiment analysis
result = sentiment_analysis(text)

print("Sentiment:", result[0]['label'])
print("Confidence Score:", result[0]['score'])

"""# BERT (not in presentation)"""

from transformers import pipeline

# Load BERT sentiment analysis pipeline
sentiment_analysis = pipeline("sentiment-analysis", model="nlptown/bert-base-multilingual-uncased-sentiment")

# Sample text
text = "This movie was absolutely fantastic!"

# Perform sentiment analysis
result = sentiment_analysis(text)

print("Sentiment:", result[0]['label'])
print("Confidence Score:", result[0]['score'])

import pandas as pd
import os
import nltk
import string
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from nltk.corpus import stopwords

df.info()

"""# SVM , Naive Bayes"""

import pandas as pd
import nltk
from transformers import pipeline
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from nltk.corpus import stopwords

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Load dataset
df = df.dropna(subset=['review_content'])

# Step 1: Use Hugging Face transformer to assign sentiment labels
sentiment_pipeline = pipeline("sentiment-analysis")

# Optional: sample if dataset is large
# df = df.sample(1000, random_state=42)

df['sentiment'] = df['review_content'].astype(str).apply(lambda x: sentiment_pipeline(x[:512])[0]['label'])

# Step 2: Clean review text
def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    tokens = [t for t in tokens if t.isalpha()]
    tokens = [t for t in tokens if t not in stopwords.words('english')]
    return ' '.join(tokens)

df['cleaned_review'] = df['review_content'].astype(str).apply(preprocess_text)

# Step 3: Vectorize
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['cleaned_review'])
y = df['sentiment']

# Step 4: Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: SVM
svm_model = SVC()
svm_model.fit(X_train, y_train)
svm_preds = svm_model.predict(X_test)

print("\n🔹 SVM Results:")
print("Accuracy:", accuracy_score(y_test, svm_preds))
print(classification_report(y_test, svm_preds))
print(confusion_matrix(y_test, svm_preds))

# Step 6: Naive Bayes
nb_model = MultinomialNB()
nb_model.fit(X_train, y_train)
nb_preds = nb_model.predict(X_test)

print("\n🔹 Naive Bayes Results:")
print("Accuracy:", accuracy_score(y_test, nb_preds))
print(classification_report(y_test, nb_preds))
print(confusion_matrix(y_test, nb_preds))

"""# voting classifier"""

import pandas as pd
import nltk
from transformers import pipeline
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.naive_bayes import MultinomialNB
from sklearn.ensemble import VotingClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from nltk.corpus import stopwords
import matplotlib.pyplot as plt
import seaborn as sns

# Download NLTK resources
nltk.download('punkt')
nltk.download('stopwords')

# Load dataset
df = df.dropna(subset=['review_content'])

# Step 1: Auto-label reviews
sentiment_pipeline = pipeline("sentiment-analysis")
df['sentiment'] = df['review_content'].astype(str).apply(lambda x: sentiment_pipeline(x[:512])[0]['label'])

# Step 2: Text preprocessing
def preprocess_text(text):
    tokens = nltk.word_tokenize(text.lower())
    tokens = [t for t in tokens if t.isalpha()]
    tokens = [t for t in tokens if t not in stopwords.words('english')]
    return ' '.join(tokens)

df['cleaned_review'] = df['review_content'].astype(str).apply(preprocess_text)

# Step 3: Vectorize
vectorizer = TfidfVectorizer(max_features=5000)
X = vectorizer.fit_transform(df['cleaned_review'])
y = df['sentiment']

# Step 4: Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Step 5: Define base models
svm_model = SVC(probability=True)
nb_model = MultinomialNB()

# Step 6: VotingClassifier (soft voting)
voting_model = VotingClassifier(estimators=[
    ('svm', svm_model),
    ('nb', nb_model)
], voting='soft')

# Train combined model
voting_model.fit(X_train, y_train)
voting_preds = voting_model.predict(X_test)

# Step 7: Evaluate
print("\n🔹 Voting Classifier Results:")
print("Accuracy:", accuracy_score(y_test, voting_preds))
print(classification_report(y_test, voting_preds))
print(confusion_matrix(y_test, voting_preds))

# Optional: Confusion matrix heatmap
conf_mat = confusion_matrix(y_test, voting_preds)
plt.figure(figsize=(6, 4))
sns.heatmap(conf_mat, annot=True, fmt="d", cmap="Blues", xticklabels=voting_model.classes_, yticklabels=voting_model.classes_)
plt.title("Confusion Matrix - Voting Classifier")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.tight_layout()
plt.show()

"""The VotingClassifier aggregates predictions from multiple classifiers (SVM, Naïve Bayes, etc.) to make a final decision.

Soft voting means that instead of choosing the most frequent class label (hard voting), it averages the predicted probabilities from all models and selects the class with the highest probability.

# rule based + ML model

# Hybrid Model Code (Rule-Based + TF-IDF + ML)
"""

import pandas as pd
import nltk
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score
from nltk.corpus import stopwords
from transformers import pipeline

nltk.download('punkt')
nltk.download('stopwords')

# Load data

df = df.dropna(subset=['review_content'])

# Label data using sentiment pipeline
sentiment_pipeline = pipeline("sentiment-analysis")
df['sentiment'] = df['review_content'].astype(str).apply(lambda x: sentiment_pipeline(x[:512])[0]['label'])

# 1. RULE-BASED FEATURES
def rule_based_features(row):
    text = row['review_content'].lower()

    # Safe conversion of rating to float
    try:
        rating_clean = re.sub("[^0-9.]", "", str(row['rating']))
        rating = float(rating_clean) if rating_clean else 0
    except:
        rating = 0

    features = {
        'review_length': len(text),
        'has_keywords': int(any(k in text for k in ['bad', 'worst', 'amazing', 'love', 'hate'])),
        'rating_score': rating
    }
    return pd.Series(features)


rule_features = df.apply(rule_based_features, axis=1)

# 2. TEXT CLEANING + TF-IDF
def clean_text(text):
    tokens = nltk.word_tokenize(text.lower())
    tokens = [t for t in tokens if t.isalpha() and t not in stopwords.words('english')]
    return ' '.join(tokens)

df['cleaned_text'] = df['review_content'].astype(str).apply(clean_text)

vectorizer = TfidfVectorizer(max_features=3000)
text_features = vectorizer.fit_transform(df['cleaned_text'])

# 3. COMBINE RULE + TEXT FEATURES
import scipy
X_combined = scipy.sparse.hstack([text_features, rule_features])
y = df['sentiment']

# 4. Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

# 5. Model: Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
preds = model.predict(X_test)

# 6. Evaluation
print("\n🔹 Hybrid Model Results:")
print("Accuracy:", accuracy_score(y_test, preds))
print(classification_report(y_test, preds))

import pandas as pd
import nltk
import re
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
from nltk.corpus import stopwords
from transformers import pipeline
import seaborn as sns
import matplotlib.pyplot as plt

nltk.download('punkt')
import nltk
nltk.download('punkt_tab')

nltk.download('stopwords')

# Load data (assuming df is already loaded as in the original code)
df = df.dropna(subset=['review_content'])

# Label data using sentiment pipeline
sentiment_pipeline = pipeline("sentiment-analysis")
df['sentiment'] = df['review_content'].astype(str).apply(lambda x: sentiment_pipeline(x[:512])[0]['label'])

# 1. RULE-BASED FEATURES
def rule_based_features(row):
    text = row['review_content'].lower()
    try:
        rating_clean = re.sub("[^0-9.]", "", str(row['rating']))
        rating = float(rating_clean) if rating_clean else 0
    except:
        rating = 0
    features = {
        'review_length': len(text),
        'has_keywords': int(any(k in text for k in ['bad', 'worst', 'amazing', 'love', 'hate'])),
        'rating_score': rating
    }
    return pd.Series(features)

rule_features = df.apply(rule_based_features, axis=1)

# 2. TEXT CLEANING + TF-IDF
def clean_text(text):
    tokens = nltk.word_tokenize(text.lower())
    tokens = [t for t in tokens if t.isalpha() and t not in stopwords.words('english')]
    return ' '.join(tokens)

df['cleaned_text'] = df['review_content'].astype(str).apply(clean_text)

vectorizer = TfidfVectorizer(max_features=3000)
text_features = vectorizer.fit_transform(df['cleaned_text'])

# 3. COMBINE RULE + TEXT FEATURES
import scipy
X_combined = scipy.sparse.hstack([text_features, rule_features])
y = df['sentiment']

# 4. Train/test split
X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)

# 5. Model: Random Forest
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)
preds = model.predict(X_test)

# 6. Evaluation
print("\n🔹 Hybrid Model Results:")
print("Accuracy:", accuracy_score(y_test, preds))
print(classification_report(y_test, preds))

# 7. Confusion Matrix
print("\n🔹 Confusion Matrix:")
cm = confusion_matrix(y_test, preds, labels=['POSITIVE', 'NEGATIVE'])
print(cm)

# Visualize Confusion Matrix
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['POSITIVE', 'NEGATIVE'], yticklabels=['POSITIVE', 'NEGATIVE'])
plt.title('Confusion Matrix for Hybrid Model')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.savefig('confusion_matrix.png')

import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import colors as mcolors

# Data setup
columns = ["Lexicon-Based", "Rule-Based", "Machine Learning", "Deep Learning"]
rows = [
    "Training Data Needed", "Speed", "Accuracy", "Context Handling",
    "Sarcasm Detection", "Domain Adaptation", "Explainability",
    "Scalability", "Best Use Case", "Example Tools"
]

data = [
    ["No", "No", "Yes (moderate)", "Yes (large)"],
    ["Very Fast", "Fast", "Moderate", "Slow (needs GPU)"],
    ["60-75%", "70-85%", "75-90%", "85-95%"],
    ["Poor", "Limited", "Good", "Excellent"],
    ["Fails", "Fails", "Partial", "Best"],
    ["Easy (add words)", "Manual updates", "Retrain needed", "Fine-tuning"],
    ["High", "High", "Medium", "Low (black-box)"],
    ["High", "Moderate", "High", "High (with resources)"],
    ["Social media", "Error logs/FAQs", "General purpose", "Complex NLP"],
    ["VADER, SentiWordNet", "Regex, SpaCy", "Scikit-learn", "BERT, HuggingFace"]
]

# DataFrame creation
df = pd.DataFrame(data, index=rows, columns=columns)

# Plot setup
fig, ax = plt.subplots(figsize=(16, 9))
ax.set_axis_off()

# Title with gradient background using patch
title = "📊 Comparison of Opinion Mining Approaches for Website Evaluation"
fig.patch.set_facecolor('#f0f4fa')
plt.title(title, fontsize=17, fontweight='bold', color='#1a1a1a', pad=20)

# Color palette
colors = {
    'header_bg': '#1f4e79',
    'header_text': 'white',
    'row_header_bg': '#dbe9f4',
    'even_row': '#f8f9fc',
    'odd_row': '#ffffff',
    'text': '#000000'
}

# Column widths for better spacing
col_widths = [0.20, 0.20, 0.26, 0.26]

# Create table
table = ax.table(
    cellText=df.values,
    rowLabels=df.index,
    colLabels=df.columns,
    cellLoc='center',
    loc='center',
    colWidths=col_widths,
    edges='closed'
)

table.auto_set_font_size(False)
table.set_fontsize(12)

# Format cells
for (row, col), cell in table.get_celld().items():
    if row == 0:
        cell.set_facecolor(colors['header_bg'])
        cell.set_text_props(color=colors['header_text'], weight='bold', size=13)
        cell.set_height(0.12)
    elif col == -1:
        cell.set_facecolor(colors['row_header_bg'])
        cell.set_text_props(weight='bold', color=colors['text'], size=12)
    else:
        bg = colors['even_row'] if row % 2 == 0 else colors['odd_row']
        cell.set_facecolor(bg)
        cell.set_text_props(color=colors['text'], size=11)
    cell.set_edgecolor('#d0d0d0')
    cell.PAD = 0.25
    cell.set_linewidth(0.6)

# Save figure
plt.savefig(
    "enhanced_sentiment_analysis_table.png",
    dpi=300,
    bbox_inches='tight',
    transparent=False
)

plt.show()

import kagglehub
import pandas as pd
import nltk
import matplotlib.pyplot as plt
import os

# Ensure all required NLTK data is downloaded
nltk.download('punkt', quiet=True)
nltk.download('stopwords', quiet=True)
nltk.download('vader_lexicon', quiet=True)

from nltk.tokenize import word_tokenize
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download the Amazon Sales Dataset
try:
    path = kagglehub.dataset_download("karkavelrajaj/amazon-sales-dataset")
    print("Path to dataset files:", path)

    # Locate the CSV file
    csv_file = os.path.join(path, 'amazon.csv')

    # Load the dataset
    df = pd.read_csv(csv_file)
except Exception as e:
    print(f"Error loading dataset: {e}")
    exit()

df.head()

df.info()